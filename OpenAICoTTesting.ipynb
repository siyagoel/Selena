{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b7e932-1f29-44a3-ad87-7b871d788d2a",
   "metadata": {},
   "source": [
    "# GPT Prompt 1 (Prompt Engineering Responses For Individual Messages):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f262fa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=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\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e29cb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /Users/siyagoel/anaconda3/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: aiohttp in /Users/siyagoel/anaconda3/lib/python3.10/site-packages (from openai==0.28) (3.8.5)\n",
      "Requirement already satisfied: tqdm in /Users/siyagoel/anaconda3/lib/python3.10/site-packages (from openai==0.28) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/siyagoel/anaconda3/lib/python3.10/site-packages (from openai==0.28) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/siyagoel/anaconda3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/siyagoel/anaconda3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/siyagoel/anaconda3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/siyagoel/anaconda3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/siyagoel/anaconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/siyagoel/anaconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/siyagoel/anaconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/siyagoel/anaconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/siyagoel/anaconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/siyagoel/anaconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ce61d4d-4636-46b7-9dd4-140edae1f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import wandb\n",
    "\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80140cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:yjfw6sgm) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">toasty-plant-5</strong> at: <a href='https://wandb.ai/serenasiya/Serena%20Urgency%20%28Singular%20Messages%29/runs/yjfw6sgm' target=\"_blank\">https://wandb.ai/serenasiya/Serena%20Urgency%20%28Singular%20Messages%29/runs/yjfw6sgm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240124_183528-yjfw6sgm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:yjfw6sgm). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898f8e065d8548dcacd00dd9eb7c5ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011125287500261847, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/amazon/redshift/Setup/wandb/run-20240124_183738-mau6cld8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/serenasiya/Serena%20Urgency%20%28CoT%20Testing%29/runs/mau6cld8' target=\"_blank\">fancy-armadillo-1</a></strong> to <a href='https://wandb.ai/serenasiya/Serena%20Urgency%20%28CoT%20Testing%29' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/serenasiya/Serena%20Urgency%20%28CoT%20Testing%29' target=\"_blank\">https://wandb.ai/serenasiya/Serena%20Urgency%20%28CoT%20Testing%29</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/serenasiya/Serena%20Urgency%20%28CoT%20Testing%29/runs/mau6cld8' target=\"_blank\">https://wandb.ai/serenasiya/Serena%20Urgency%20%28CoT%20Testing%29/runs/mau6cld8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='Serena Urgency (CoT Testing)')\n",
    "prediction_table = wandb.Table(columns=[\"prompt\", \"completion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0767b497-b7bf-4d90-a011-0509b915cd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", preferably within the next couple of hours. As an MBA student, it is important for her to prioritize meetings and respond promptly to important messages. Additionally, the sender has mentioned that they have a class at 12:30 pm, so it is likely that they need to discuss something important with Saloni before that time. Therefore, responding within the next couple of hours would allow enough time for a productive conversation. Waiting longer than a day may cause the sender to miss their class or delay important discussions. It is important for Saloni to prioritize urgent messages and respond in a timely manner to maintain effective communication and productivity.\n"
     ]
    }
   ],
   "source": [
    "gpt_prompt = \"As a MBA student named Saloni at Stanford University, how urgently would you to respond to the following message that is from bryanhpchiang@gmail.com with the subject “Chat! (one hour, couple hours, one day, a couple days, one week, a couple weeks, one month, never).” The message was sent on September 19, 2023 at 10:40 am Message: sorry for the late heads up  realized i have class 12:30-1:30  does 1:45 work?\"\n",
    "\n",
    "cot_steps = [\n",
    " \"Note that Saloni is a MBA student who needs to prioritize meetings\",\n",
    " \"The sender is specifically someone who Saloni needs to talk to urgently\",\n",
    " \"Saloni should respond to this message soon\",\n",
    "]\n",
    "# Combine prompt and CoT steps\n",
    "gpt_prompt = \"\\n\".join([gpt_prompt] + cot_steps)\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=gpt_prompt,\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    ")\n",
    "\n",
    "\n",
    "print(response['choices'][0]['text'])\n",
    "prediction_table.add_data(gpt_prompt,response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8fdd508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", but it is not urgent. She can take her time and respond within a couple of days or even a week. As an MBA student, Saloni may have a busy schedule and may not be able to attend the event, but she can still show her support by responding to the message and thanking the sender for the invitation. She can also express her support for the LGBTQ+ community and explain that she may not be able to attend due to her schedule. It is important for Saloni to respond eventually to show her support and solidarity with the South Asian LGBTQ+ community, but it is not an urgent matter that requires an immediate response.\n"
     ]
    }
   ],
   "source": [
    "gpt_prompt = \"As a MBA student named Saloni at Stanford University, how urgently would you respond to the following message that is from ngupta23@stanford.edu with the subject “SABSA celebrates Pride” ing message that is from bryanhpchiang@gmail.com with the subject “Chat! (one hour, couple hours, one day, a couple days, one week, a couple weeks, one month, never)? The message was sent on September 2, 2023 at 12:54 pm. Message: Dear Fellow South Asians. We wanted to share a *personal invite* for the Pride Party tomorrow. Would love to see each one of you at the party to reinforce the message that the South Asian community stands in solidarity with our LGBTQ+ members.\"\n",
    "\n",
    "cot_steps = [\n",
    " \"Note that Saloni is a MBA student who does not like going to community events\",\n",
    " \"The sender is specifically someone who Saloni does not need to talk to urgently\",\n",
    " \"Saloni should respond to this message eventually\",\n",
    "]\n",
    "# Combine prompt and CoT steps\n",
    "gpt_prompt = \"\\n\".join([gpt_prompt] + cot_steps)\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=gpt_prompt,\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    ")\n",
    "\n",
    "\n",
    "print(response['choices'][0]['text'])\n",
    "prediction_table.add_data(gpt_prompt,response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9c94988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", but it does not require an urgent response. As an MBA student who loves Matcha, Saloni may be interested in attending the event, but it is not a pressing matter that requires an immediate response. She can take her time to check her schedule and see if she can attend the event, and respond accordingly. She can also take the time to thank the sender for the invitation and express her interest in attending. However, since the event is next week, Saloni should respond within a couple of days to confirm her attendance and secure her spot. \n"
     ]
    }
   ],
   "source": [
    "gpt_prompt = \"As a MBA student named Saloni at Stanford University, how urgently would you respond to the following message that is from wilkinsj@stanford.edu with the subject line “Matcha Testing and Lunch!”  ing message that is from bryanhpchiang@gmail.com with the subject “Chat! (one hour, couple hours, one day, a couple days, one week, a couple weeks, one month, never)? The message was sent on September 23, 2023 at 1:20 pm. Message: Cuzen Matcha, is coming to campus to host a matcha tasting event! The event is next week from 12pm - 1pm in C102 on   Monday, January 23rd. Sandwiches from Mendocino Farms will be provided for the first 30 attendees.\"\n",
    "\n",
    "cot_steps = [\n",
    " \"Note that Saloni is a MBA student who loves Matcha\",\n",
    " \"The sender is specifically someone who Saloni does not need to talk to urgently\",\n",
    " \"Saloni should respond to this message eventually\",\n",
    "]\n",
    "# Combine prompt and CoT steps\n",
    "gpt_prompt = \"\\n\".join([gpt_prompt] + cot_steps)\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=gpt_prompt,\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    ")\n",
    "\n",
    "\n",
    "print(response['choices'][0]['text'])\n",
    "prediction_table.add_data(gpt_prompt,response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f944e5e-2e23-4743-a3cc-adfc023e3647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s automated message, as it is not urgent and does not require a response. However, if Saloni would like to review the introduction to Spur, she could respond to Bryan Chiang's email and schedule a time to chat within the next couple of days. This would allow her to stay on top of her responsibilities and not delay the review process.\n"
     ]
    }
   ],
   "source": [
    "gpt_prompt = \"As a MBA student named Saloni at Stanford University, how urgently would you respond to the following message that is from do-not-reply@sybill.ai with the subject line “Introduction to Spur is ready for review” ing message that is from bryanhpchiang@gmail.com with the subject “Chat! (one hour, couple hours, one day, a couple days, one week, a couple weeks, one month, never)? The message was sent on September 2, 2023 at 2:15 am. Message: Outcome  The meeting was a discussion between Jenna Kertz, Director of Product Management at Beautiful.ai, Travis Millard from Beautiful.ai, and Saloni Goel from Stanford University. They discussed the growth analysis of Beautiful.ai, focusing on user engagement, retention, and conversion rates.\"\n",
    "\n",
    "cot_steps = [\n",
    " \"Note that Sybill is an assistant who sends automated messages\",\n",
    " \"Saloni does not need tor espond to Sybill\",\n",
    "]\n",
    "# Combine prompt and CoT steps\n",
    "gpt_prompt = \"\\n\".join([gpt_prompt] + cot_steps)\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=gpt_prompt,\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    ")\n",
    "\n",
    "\n",
    "print(response['choices'][0]['text'])\n",
    "prediction_table.add_data(gpt_prompt,response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c499498-8583-46a1-a516-4fabf93df062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "As a MBA student at Stanford, I would respond to this message urgently, within a couple of hours. As an entrepreneur, it is important for me to network and form connections with other entrepreneurs and potential co-founders. Additionally, the fact that the message is about entrepreneurship and is important to me makes it even more urgent for me to respond promptly. I would prioritize this meeting and make time to meet with Mike as soon as possible.\n"
     ]
    }
   ],
   "source": [
    "gpt_prompt = \"As a MBA student named Saloni at Stanford University, how urgently would you respond to the following message that is from mike@vooma.ai with the subject “Mike <> Saloni” ing message that is from bryanhpchiang@gmail.com with the subject “Chat! (one hour, couple hours, one day, a couple days, one week, a couple weeks, one month, never)? The message was sent on September 1, 2023 at 10:38 pm. Message: “Saloni, meet my co-founder Mike. It would be great if you both found some time today to meet! Saloni, I'm just jumping into meetings, but I'll separately set up time with you to speak further later today.\"\n",
    "\n",
    "cot_steps = [\n",
    " \"Saloni is an entrepreneur at Stanford\",\n",
    " \"This message is about entrepreneurship and is important to her\",\n",
    "]\n",
    "# Combine prompt and CoT steps\n",
    "gpt_prompt = \"\\n\".join([gpt_prompt] + cot_steps)\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=gpt_prompt,\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    ")\n",
    "\n",
    "\n",
    "print(response['choices'][0]['text'])\n",
    "prediction_table.add_data(gpt_prompt,response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "963506ef-6546-463e-8f64-195109cc460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to the survey, so she would respond with a timeframe of a couple days. She would reply with a message such as, \"Hi Bryan, thank you for reaching out. I am currently tied up with other tasks and will not be able to complete the survey until a couple days from now. I apologize for any inconvenience this may cause. Thank you for understanding.\" \n"
     ]
    }
   ],
   "source": [
    "gpt_prompt = \"As a MBA student named Saloni at Stanford University, how urgently would you respond to the following message that is from siranj@stanford.edu with the subject line “Fill out a survey for my class” ing message that is from bryanhpchiang@gmail.com with the subject “Chat! (one hour, couple hours, one day, a couple days, one week, a couple weeks, one month, never)? The message was sent on September 2, 2023 at 5:15 pm. Message: “Hi!  Like many others, I'm taking a class on Reputation Management and would really appreciate if you could answer a few questions about what you think of me.  It would really help me understand how I can be a better leader, classmate, and friend.\"\n",
    "\n",
    "cot_steps = [\n",
    " \"Saloni values giving important information to her colleagues but is busy with other tasks\",\n",
    " \"She needs to complete other tasks before she can respond\",\n",
    "]\n",
    "# Combine prompt and CoT steps\n",
    "gpt_prompt = \"\\n\".join([gpt_prompt] + cot_steps)\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=gpt_prompt,\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    ")\n",
    "\n",
    "\n",
    "print(response['choices'][0]['text'])\n",
    "prediction_table.add_data(gpt_prompt,response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "edc13ce5-c0eb-4205-8742-325ac4ac00fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and a meeting request. As a MBA student at Stanford University, I would respond to this message as soon as possible, preferably within a day or two. The opportunity to potentially gain a customer and discuss a topic that is of interest to both parties is valuable and should not be delayed. Additionally, the mention of potentially meeting in person or via Zoom adds a level of urgency as it suggests that the sender is ready to discuss the topic and move forward with potential business opportunities. As an entrepreneur, it is important to be proactive and responsive in order to capitalize on potential opportunities and build valuable connections. Therefore, I would prioritize responding to this message in a timely manner.\n"
     ]
    }
   ],
   "source": [
    "gpt_prompt = \"As a MBA student named Saloni at Stanford University, how urgently would you respond to the following message that is from mvargas@innovationendeavors.com with the subject “390 opportunity - request to meet” ing message that is from bryanhpchiang@gmail.com with the subject “Chat! (one hour, couple hours, one day, a couple days, one week, a couple weeks, one month, never)? The message was sent on September 14, 2023 at 4:40 pm. Message: “Saloni, The topic is definitely interesting. If you can solve this, I would be your first customer! Happy to chat through this. CCing Marissa to find a time for a Zoom or an in person. Thanks\"\n",
    "\n",
    "cot_steps = [\n",
    " \"Saloni is an entrepreneur\",\n",
    " \"This email is an important and urgent email regarding a potential customer\",\n",
    "]\n",
    "# Combine prompt and CoT steps\n",
    "gpt_prompt = \"\\n\".join([gpt_prompt] + cot_steps)\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=gpt_prompt,\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    ")\n",
    "\n",
    "\n",
    "print(response['choices'][0]['text'])\n",
    "prediction_table.add_data(gpt_prompt,response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89d55b98-989e-4c56-b3e3-86a6357ab209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". While the message is important and Saloni should take action before the expiration date, she can prioritize other tasks that may be more pressing at the moment. However, she should not wait too long and should make sure to check her balance and request any refunds before the expiration date. It is important for Saloni to make the most of her available funds and not let them go to waste. Therefore, she should respond to the message within a reasonable timeframe, such as within a week or two at the latest. Waiting longer than that may result in her missing out on the opportunity to request a refund for any unused meal blocks.\n"
     ]
    }
   ],
   "source": [
    "gpt_prompt = \"As a MBA student named Saloni at Stanford University, how urgently would you respond to the following message that is from diningplans@stanford.edu with the subject “Final reminder grad meal plan expiration” ing message that is from bryanhpchiang@gmail.com with the subject “Chat! (one hour, couple hours, one day, a couple days, one week, a couple weeks, one month, never)? The message was sent on August 31, 2023 at 9:41 pm. Message: “We want to take this opportunity to thank you for your support of the Graduate Meal Plan and it has been our pleasure to serve you. As we approach the end of summer quarter, we would like to remind you that any remaining balance on your Graduate Meal Plan purchased before August 14, 2023, will expire at the end of the day on August 31,2023.Please review your balance throughout the remainder of summer quarter to plan your spending accordingly and ensure that you make the most of your available funds before the expiration date. You can check your current balances at any time by logging into your student account at: https://rdeapps.stanford.edu/MyMealPlan/. Refunds for unused graduate meal blocks may be requested at any time until the expiration date of August 31, 2023.\"\n",
    "\n",
    "cot_steps = [\n",
    " \"Saloni needs to approve her meal plan\",\n",
    " \"Saloni can wait a couple days before doing this task\",\n",
    "]\n",
    "# Combine prompt and CoT steps\n",
    "gpt_prompt = \"\\n\".join([gpt_prompt] + cot_steps)\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=gpt_prompt,\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    ")\n",
    "\n",
    "\n",
    "print(response['choices'][0]['text'])\n",
    "prediction_table.add_data(gpt_prompt,response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45e38946-ef5b-4daf-a7c9-88d4c5870af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and does not need to respond to this message. Therefore, she does not need to respond at all.\n"
     ]
    }
   ],
   "source": [
    "gpt_prompt = \"As a MBA student named Saloni at Stanford University, how urgently would you to respond to the following message that is from rachelak@stanford.edu with a subject line “Rachel and Mara’s Birthday” ing message that is from bryanhpchiang@gmail.com with the subject “Chat! (one hour, couple hours, one day, a couple days, one week, a couple weeks, one month, never)? The message was sent on September 8, 2023 at 11:11 am. How urgently should you respond to this message (one day, one week, or one month)?  Message: “Hi friends! Looking forward to see you all tonight. Just a quick note for   those who have not been to Alpine Inn before, its a no reservation kind of   place, so we are getting there a bit early to snag tables, but definitely think of this as come & go as you need.\"\n",
    "\n",
    "cot_steps = [\n",
    " \"Saloni does not know Maria and Rachel\",\n",
    " \"As a result, she is not goint to their birthday party\",\n",
    "]\n",
    "# Combine prompt and CoT steps\n",
    "gpt_prompt = \"\\n\".join([gpt_prompt] + cot_steps)\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=gpt_prompt,\n",
    "  temperature=0.5,\n",
    "  max_tokens=256,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    ")\n",
    "\n",
    "\n",
    "print(response['choices'][0]['text'])\n",
    "prediction_table.add_data(gpt_prompt,response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac3afc1e-e186-4cea-8da3-71e5109ac760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.025 MB of 0.025 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fancy-armadillo-1</strong> at: <a href='https://wandb.ai/serenasiya/Serena%20Urgency%20%28CoT%20Testing%29/runs/mau6cld8' target=\"_blank\">https://wandb.ai/serenasiya/Serena%20Urgency%20%28CoT%20Testing%29/runs/mau6cld8</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240124_183738-mau6cld8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({'predictions': prediction_table})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
